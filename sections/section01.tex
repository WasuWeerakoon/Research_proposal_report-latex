\section{Introduction}

\subsection{Background of the Study}
Artificial Intelligence (AI) has become a cornerstone of modern technological development, powering applications from healthcare diagnostics to autonomous vehicles. Among the many AI approaches, neural networks—particularly deep learning models—have gained significant traction due to their ability to achieve state-of-the-art performance in complex tasks such as image recognition, speech processing, and natural language understanding. However, as the demand for AI grows, so does the need for efficient, scalable, and sustainable computational models capable of operating effectively on edge and embedded devices.

In response to these demands, Spiking Neural Networks (SNNs) have emerged as a promising alternative to conventional Artificial Neural Networks (ANNs). Inspired by the way biological neurons communicate through discrete spikes, SNNs mimic brain-like event-driven processing, offering the potential for low-power and highly efficient computation. At the same time, ARM-based architectures dominate mobile, IoT, and embedded systems, making them the backbone of energy-conscious computing platforms. Investigating how SNNs can be implemented on ARM systems is therefore crucial for bridging neuroscience-inspired AI with practical real-world deployment.

Recent research has demonstrated considerable progress in improving the accuracy and latency of SNNs, making them more competitive with traditional deep learning models. Event-driven sensors and neuromorphic computing have also created new opportunities for real-time, energy-efficient applications. Despite these advancements, challenges remain: SNNs often face difficulties in model training, hardware–software integration, and achieving comparable accuracy without consuming significant resources. Moreover, while ARM processors are pervasive, relatively little research has focused on the direct deployment of SNNs on these architectures, leaving critical gaps in performance evaluation and optimization strategies.

This gap highlights the need for systematic investigation into the feasibility and limitations of deploying SNNs on ARM platforms. Without such studies, the potential of SNNs for real-time, low-power edge computing remains largely theoretical. By examining how SNNs perform on different ARM-based systems, this research aims to provide practical insights, benchmark data, and optimization guidelines that could accelerate the adoption of brain-inspired AI in resource-constrained environments. Ultimately, this study seeks to bridge the divide between the promise of SNNs and the practical realities of embedded AI deployment.



\subsection{Problem Statement}
Artificial Intelligence (AI) is increasingly shifting toward real-time applications on edge devices such as smartphones, IoT systems, and embedded platforms. These devices require models that are not only accurate but also energy-efficient, since traditional deep learning architectures consume significant computational power and battery resources. Spiking Neural Networks (SNNs), inspired by the human brain’s event-driven signaling, have emerged as a promising alternative due to their ability to achieve computation with lower energy costs. Despite their potential, there is a noticeable gap when it comes to practical deployment: most research and optimizations for SNNs have been tested on high-performance hardware, leaving their behavior on resource-constrained platforms like ARM largely unexplored. Without addressing this gap, the widespread adoption of energy-efficient, brain-inspired AI for real-world embedded applications will remain limited.

Prior research has shown that SNNs can significantly reduce energy consumption compared to conventional Artificial Neural Networks (ANNs), particularly in neuromorphic hardware and GPU-based systems (Bouvier \& Bouzerdoum, 2019; Bu et al., 2022). Frameworks such as SpiNeMap (Balaji et al., 2019) and evaluation tools like NAXT (Abderrahmane et al., 2020) have advanced the mapping and benchmarking of SNNs. However, these studies mainly focus on specialized neuromorphic chips or general-purpose processors, overlooking ARM-based architectures, which dominate the embedded and mobile computing market. As a result, there is limited empirical evidence and optimization guidelines for effectively running SNNs on ARM systems. This shortcoming prevents developers from fully understanding the trade-offs, bottlenecks, and feasibility of deploying SNNs in practical edge scenarios.

The core problem is that while SNNs are recognized as energy-efficient alternatives to conventional neural networks, their implementation on ARM-based systems remains underexplored and poorly understood. The lack of systematic investigation into feasibility, performance, and limitations creates a significant barrier to realizing energy-efficient, brain-inspired AI on the world’s most widely used embedded platform. If this issue is not addressed, the potential benefits of SNNs—such as real-time low-power processing for edge and IoT devices—cannot be fully achieved. Therefore, this research aims to systematically investigate the feasibility and limitations of implementing Spiking Neural Networks on ARM architecture, providing empirical benchmarks and optimization strategies that can guide future embedded AI development.


\subsection{Aim, Objectives and Questions}

\begin{itemize}
	\item Aim: To systematically investigate the feasibility and limitations of implementing Spiking Neural Networks on ARM architecture by designing, deploying, and benchmarking SNN models across a representative range of ARM-based platforms.
	
	\item Objectives:
	\begin{itemize}
		\item 1. To conduct a comprehensive review of existing SNN models, software frameworks, and deployment methodologies suitable for ARM-based systems.
		
		\item 2. To design and implement benchmark SNN models for a standard machine-learning task using a selected SNN framework compatible with ARM architecture.
		
		\item 3. To deploy the implemented SNNs on a curated set of ARM platforms and systematically measure key performance metrics, including accuracy, inference latency, and power  consumption.
		
		\item 4. To Evaluate the feasibility of SNNs on ARM by examining performance data, identifying key bottlenecks, and defining operational limits.
	\end{itemize} 
	\item Research Questions:
	\begin{itemize}
		\item 1. What are the technical and computational challenges of implementing Spiking Neural Networks on ARM Architecture?
		\item 2. How do SNN implementations on ARM Architecture compare with conventional ANN's in terms of performance, energy efficiency and latency?
		\item 3. What optimizations or adaptations are required to improve the feasibility of SNNs on ARM Systems?
		\item 4. What methods can be used to evaluate the feasibility of SNNs on ARM Architecture?
		\item 5. How feasible is the deployment of SNNs on ARM Architecture?
	\end{itemize}
\end{itemize}

\subsection{Rationale of the Study}
The rapid expansion of AI applications into mobile, IoT, and edge computing has created an urgent demand for models that can operate with high efficiency on resource-limited platforms. Conventional Artificial Neural Networks (ANNs), while powerful, are often unsuitable for these environments due to their high energy consumption and latency. Spiking Neural Networks (SNNs) represent a new frontier in AI research, inspired by the brain’s efficient, event-driven processing. With ARM processors powering the majority of mobile and embedded devices globally, exploring the deployment of SNNs on ARM has become a timely and highly relevant problem. Addressing this research now is essential, as the need for low-power, real-time AI solutions continues to grow rapidly in both industry and academia.

While previous research has made progress in optimizing SNNs on specialized neuromorphic chips and high-performance GPUs, there is a clear lack of systematic studies focusing on ARM-based architectures. This gap is problematic because ARM platforms dominate everyday devices, from smartphones to embedded sensors, and are central to the growth of smart technologies. Current solutions fail to provide reliable benchmarks, performance guidelines, or optimization strategies for SNNs in these settings, leaving a major disconnect between theoretical research and practical deployment.

This study is motivated by the belief that bridging this gap can have significant real-world impact. By investigating the feasibility and limitations of SNNs on ARM, the research aims to provide practical insights that could make energy-efficient, brain-inspired AI accessible to a wide range of low-power devices. For countries like Sri Lanka, where cost-effective and sustainable technology solutions are vital, this work could help advance industries such as agriculture, healthcare, and IoT-driven services. Beyond academic significance, this project reflects our group’s interest in future-ready AI methods that combine innovation with practicality, contributing to both global AI development and local technological progress.


\subsection{Significance of the Study}
This research holds value for both academic and practical communities. Academically, it contributes new knowledge by systematically exploring the feasibility of deploying Spiking Neural Networks (SNNs) on ARM architectures — a direction that has received limited attention compared to neuromorphic chips and GPUs. By benchmarking performance, energy efficiency, and limitations, the study provides a foundation for future researchers to build on, advancing the understanding of brain-inspired AI in embedded computing. It not only extends theoretical discussions but also offers concrete empirical data that fills a critical research gap.

From a practical perspective, this study benefits industries and societies that increasingly rely on low-power, real-time AI systems. ARM processors dominate mobile phones, IoT devices, and embedded platforms used worldwide. By providing optimization strategies and performance insights for SNNs on ARM, this research can enable developers to design applications that are both energy-efficient and responsive. Potential applications include smart healthcare devices, precision agriculture systems, autonomous robotics, and wearable technology — areas where reducing power consumption is vital.

Furthermore, the study introduces improvements to existing methods by aligning neuromorphic-inspired AI with the constraints of widely available hardware. This alignment makes advanced AI more accessible for developing countries like Sri Lanka, where affordable, energy-conscious solutions are essential. In this way, the research not only helps global technological innovation but also directly supports local communities and industries by enabling sustainable and practical AI deployment.

Ultimately, the findings of this research can guide future academic projects, inspire further exploration into low-power AI, and serve as a stepping stone toward products, systems, and services that bring real-world benefits to diverse groups such as students, farmers, patients, and everyday technology users.
 

\subsection{Scope and Limitations of the Study}
This research focuses on investigating the feasibility and limitations of implementing Spiking Neural Networks (SNNs) on ARM-based architectures. The study will design, deploy, and benchmark selected SNN models on representative ARM platforms, including Raspberry Pi, NVIDIA Jetson Nano, and STM32 microcontrollers. Publicly available neuromorphic datasets such as N-MNIST, DVS Gesture, and EEG Motor Movement/Imagery will be used for evaluating performance in tasks like image and gesture recognition. Key performance metrics including accuracy, inference latency, and energy consumption will be measured. The study is limited to ARM-based systems as the primary computing environment, emphasizing real-time and low-power edge computing scenarios rather than large-scale cloud or GPU platforms.

The study faces certain constraints due to technical, resource, and time boundaries. First, the hardware platforms available for experimentation are limited to a small selection of ARM-based boards, which may not capture the full diversity of ARM processors used in industry. Second, only specific datasets are considered, meaning results may not fully generalize across all application domains of SNNs. Third, training large-scale SNN models is computationally intensive and may not be feasible within the time frame, requiring reliance on smaller benchmark models. Additionally, the study assumes stable software support from existing SNN frameworks, though these frameworks are still evolving and may impose restrictions on functionality. Finally, due to the academic scope and timeline of the project, the research will primarily focus on experimental validation rather than deployment into real-world commercial products.
